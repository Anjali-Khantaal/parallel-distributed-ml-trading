{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2604b98e-4cfc-4f75-afab-b7ff32914ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "from dask_ml.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "import os\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89737170-ac9d-4510-9e16-0bbadea522c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import talib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec9fda93-54a6-4e36-895a-fbe25750b422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please update inputs in distributed_utils.py with the same inputs as here\n",
    "DATA_DIR = \"processed_data\"\n",
    "MODEL_DIR = \"models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5f01af0-3b32-45e1-8fd3-c436d79c2bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(ticker):\n",
    "    \"\"\"\n",
    "    Load and prepare data for a given ticker. Includes inspection of NaN values before dropping them.\n",
    "\n",
    "    Parameters:\n",
    "        ticker (str): Stock ticker.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Features (X) and target (y).\n",
    "    \"\"\"\n",
    "    file_path = f\"{DATA_DIR}/{ticker}_historical_prices_.csv\"\n",
    "    df = dd.read_csv(file_path)\n",
    "    \n",
    "    # Ensure necessary columns exist\n",
    "    required_columns = [\"Close\", \"SMA_20\", \"EMA_20\", \"RSI\", \"Volatility\", \"Close_lag_1\", \"Close_lag_2\", \"Momentum\"]\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Column {col} missing in {ticker} dataset.\")\n",
    "\n",
    "    # df[\"MACD\"], df[\"MACD_signal\"], _ = talib.MACD(df[\"Close\"].to_numpy())\n",
    "    \n",
    "    # Inspect NaN values\n",
    "    print(f\"\\nInspecting NaN values for {ticker}:\")\n",
    "    nan_summary = df.isna().sum().compute()  # Get the total number of NaN values per column\n",
    "    print(nan_summary)\n",
    "    \n",
    "    # Check rows with NaN\n",
    "    print(f\"\\nRows with NaN values (sample) for {ticker}:\")\n",
    "    rows_with_nan = df[df.isna().any(axis=1)].compute()\n",
    "    print(rows_with_nan.head())  # Print the first few rows with NaN values\n",
    "    \n",
    "    # Features and target\n",
    "    print(f\"\\nDropping rows with NaN values for {ticker}...\")\n",
    "    df = df.dropna()  # Drop rows with NaN values\n",
    "    print(f\"Remaining rows after dropping NaN: {len(df)}\")\n",
    "    \n",
    "    X = df[[\"SMA_20\", \"EMA_20\", \"RSI\", \"RSI_SMA_Ratio\", \"Volatility\", \"Close_lag_1\", \"Close_lag_2\", \"Momentum\"]]\n",
    "    # y = (df[\"Close\"].shift(-1) > df[\"Close\"]).astype(int)  # 1 if price goes up, 0 otherwise\n",
    "    y = (df[\"Close\"].shift(-5) > df[\"Close\"]).astype(int)\n",
    "    return X, y\n",
    "\n",
    "def train_random_forest(ticker):\n",
    "    \"\"\"\n",
    "    Train an improved Random Forest model for a specific stock ticker.\n",
    "    Includes:\n",
    "    - Data split into train and test sets.\n",
    "    - Hyperparameter tuning.\n",
    "    - Class balancing.\n",
    "    - Improved feature engineering.\n",
    "\n",
    "    Parameters:\n",
    "        ticker (str): Stock ticker symbol.\n",
    "\n",
    "    Returns:\n",
    "        str: Path to the saved model.\n",
    "    \"\"\"\n",
    "    print(f\"\\nTraining Random Forest model for {ticker}...\")\n",
    "\n",
    "    # Step 1: Load and Prepare Data\n",
    "    X, y = load_and_prepare_data(ticker)\n",
    "    X = X.compute()  # Convert Dask DataFrame to Pandas\n",
    "    y = y.compute()\n",
    "\n",
    "    # Inspect class balance\n",
    "    print(f\"Class distribution for {ticker}:\")\n",
    "    print(y.value_counts())\n",
    "    smote = SMOTE(random_state=42)\n",
    "    \n",
    "    # Step 2: Split the Data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "    # # Step 2: Train-Test Split\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # Step 3: Define the Model\n",
    "    model = RandomForestClassifier(random_state=42, class_weight=\"balanced\")\n",
    "\n",
    "    # Step 4: Hyperparameter Grid\n",
    "    param_grid = {\n",
    "        \"n_estimators\": [50, 100, 200],\n",
    "        \"max_depth\": [5, 10, 15],\n",
    "        \"min_samples_split\": [2, 5, 10]\n",
    "    }\n",
    "\n",
    "    # Step 5: Hyperparameter Tuning with GridSearchCV\n",
    "    print(f\"Performing grid search for {ticker}...\")\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=model,\n",
    "        param_grid=param_grid,\n",
    "        cv=3,\n",
    "        scoring=\"accuracy\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    grid_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "    # Step 6: Evaluate the Model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(f\"Best parameters for {ticker}: {grid_search.best_params_}\")\n",
    "\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy for {ticker}: {accuracy:.2f}\")\n",
    "\n",
    "    # Detailed Classification Report\n",
    "    print(f\"Classification Report for {ticker}:\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Step 7: Save the Model\n",
    "    model_path = f\"{MODEL_DIR}/{ticker}_improved_random_forest.pkl\"\n",
    "    joblib.dump(best_model, model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "    return model_path\n",
    "\n",
    "def train_models_for_all_tickers(tickers):\n",
    "    \"\"\"\n",
    "    Train Random Forest models for all tickers in parallel using Dask.\n",
    "\n",
    "    Parameters:\n",
    "        tickers (list): List of stock tickers.\n",
    "    \"\"\"\n",
    "    # Each ticker's training task is executed in parallel using dask.delayed.\n",
    "    futures = [dask.delayed(train_random_forest)(ticker) for ticker in tickers]\n",
    "    results = dask.compute(*futures)  # Run tasks in parallel\n",
    "    print(\"All models trained and saved:\")\n",
    "    for result in results:\n",
    "        print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bd24d00-9473-407d-af0d-cbc58d95ea16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Random Forest model for AAPL...\n",
      "\n",
      "Training Random Forest model for MSFT...\n",
      "\n",
      "Training Random Forest model for TSLA...\n",
      "\n",
      "Training Random Forest model for GOOGL...\n",
      "\n",
      "Inspecting NaN values for AAPL:\n",
      "\n",
      "Inspecting NaN values for TSLA:\n",
      "\n",
      "Inspecting NaN values for MSFT:\n",
      "\n",
      "Inspecting NaN values for GOOGL:\n",
      "Unnamed: 0          0\n",
      "Price               0\n",
      "Close               0\n",
      "High                0\n",
      "Low                 0\n",
      "Open                0\n",
      "Volume              0\n",
      "SMA_20             19\n",
      "EMA_20              0\n",
      "RSI                13\n",
      "Bollinger_Upper    19\n",
      "Bollinger_Lower    19\n",
      "10_day_MA           9\n",
      "50_day_MA          49\n",
      "RSI_SMA_Ratio      19\n",
      "Volatility         19\n",
      "Close_lag_1         1\n",
      "Close_lag_2         2\n",
      "Momentum            5\n",
      "dtype: int64\n",
      "\n",
      "Rows with NaN values (sample) for AAPL:\n",
      "Unnamed: 0          0\n",
      "Price               0\n",
      "Close               0\n",
      "High                0\n",
      "Low                 0\n",
      "Open                0\n",
      "Volume              0\n",
      "SMA_20             19\n",
      "EMA_20              0\n",
      "RSI                13\n",
      "Bollinger_Upper    19\n",
      "Bollinger_Lower    19\n",
      "10_day_MA           9\n",
      "50_day_MA          49\n",
      "RSI_SMA_Ratio      19\n",
      "Volatility         19\n",
      "Close_lag_1         1\n",
      "Close_lag_2         2\n",
      "Momentum            5\n",
      "dtype: int64\n",
      "\n",
      "Rows with NaN values (sample) for GOOGL:\n",
      "Unnamed: 0          0\n",
      "Price               0\n",
      "Close               0\n",
      "High                0\n",
      "Low                 0\n",
      "Open                0\n",
      "Volume              0\n",
      "SMA_20             19\n",
      "EMA_20              0\n",
      "RSI                13\n",
      "Bollinger_Upper    19\n",
      "Bollinger_Lower    19\n",
      "10_day_MA           9\n",
      "50_day_MA          49\n",
      "RSI_SMA_Ratio      19\n",
      "Volatility         19\n",
      "Close_lag_1         1\n",
      "Close_lag_2         2\n",
      "Momentum            5\n",
      "dtype: int64\n",
      "\n",
      "Rows with NaN values (sample) for TSLA:\n",
      "Unnamed: 0          0\n",
      "Price               0\n",
      "Close               0\n",
      "High                0\n",
      "Low                 0\n",
      "Open                0\n",
      "Volume              0\n",
      "SMA_20             19\n",
      "EMA_20              0\n",
      "RSI                13\n",
      "Bollinger_Upper    19\n",
      "Bollinger_Lower    19\n",
      "10_day_MA           9\n",
      "50_day_MA          49\n",
      "RSI_SMA_Ratio      19\n",
      "Volatility         19\n",
      "Close_lag_1         1\n",
      "Close_lag_2         2\n",
      "Momentum            5\n",
      "dtype: int64\n",
      "\n",
      "Rows with NaN values (sample) for MSFT:\n",
      "   Unnamed: 0       Price      Close       High        Low       Open  \\\n",
      "0           0  2010-01-04  15.627781  15.696601  15.565196  15.632768   \n",
      "1           1  2010-01-05  15.558962  15.654961  15.497873  15.638504   \n",
      "2           2  2010-01-06  15.166741  15.605591  15.119366  15.605591   \n",
      "3           3  2010-01-07  14.813665  15.210127  14.777511  15.195165   \n",
      "4           4  2010-01-08  15.011148  15.041817  14.689241  14.761303   \n",
      "\n",
      "      Volume  SMA_20     EMA_20  RSI  Bollinger_Upper  Bollinger_Lower  \\\n",
      "0   78169752     NaN  15.627781  NaN              NaN              NaN   \n",
      "1  120067812     NaN  15.621227  NaN              NaN              NaN   \n",
      "2  158988852     NaN  15.577942  NaN              NaN              NaN   \n",
      "3  256315428     NaN  15.505154  NaN              NaN              NaN   \n",
      "4  188783028     NaN  15.458106  NaN              NaN              NaN   \n",
      "\n",
      "   10_day_MA  50_day_MA  RSI_SMA_Ratio  Volatility  Close_lag_1  Close_lag_2  \\\n",
      "0        NaN        NaN            NaN         NaN          NaN          NaN   \n",
      "1        NaN        NaN            NaN         NaN    15.627781          NaN   \n",
      "2        NaN        NaN            NaN         NaN    15.558962    15.627781   \n",
      "3        NaN        NaN            NaN         NaN    15.166741    15.558962   \n",
      "4        NaN        NaN            NaN         NaN    14.813665    15.166741   \n",
      "\n",
      "   Momentum  \n",
      "0       NaN  \n",
      "1       NaN  \n",
      "2       NaN  \n",
      "3       NaN  \n",
      "4       NaN  \n",
      "\n",
      "Dropping rows with NaN values for GOOGL...\n",
      "   Unnamed: 0       Price      Close       High        Low       Open  \\\n",
      "0           0  2010-01-04  23.300680  23.413607  23.029654  23.052240   \n",
      "1           1  2010-01-05  23.308210  23.413610  23.067299  23.225398   \n",
      "2           2  2010-01-06  23.165171  23.398554  22.976958  23.247983   \n",
      "3           3  2010-01-07  22.924257  23.112470  22.728516  23.059769   \n",
      "4           4  2010-01-08  23.082352  23.247978  22.766155  22.796270   \n",
      "\n",
      "     Volume  SMA_20     EMA_20  RSI  Bollinger_Upper  Bollinger_Lower  \\\n",
      "0  38409100     NaN  23.300680  NaN              NaN              NaN   \n",
      "1  49749600     NaN  23.301397  NaN              NaN              NaN   \n",
      "2  58182400     NaN  23.288423  NaN              NaN              NaN   \n",
      "3  50559700     NaN  23.253741  NaN              NaN              NaN   \n",
      "4  51197400     NaN  23.237418  NaN              NaN              NaN   \n",
      "\n",
      "   10_day_MA  50_day_MA  RSI_SMA_Ratio  Volatility  Close_lag_1  Close_lag_2  \\\n",
      "0        NaN        NaN            NaN         NaN          NaN          NaN   \n",
      "1        NaN        NaN            NaN         NaN    23.300680          NaN   \n",
      "2        NaN        NaN            NaN         NaN    23.308210    23.300680   \n",
      "3        NaN        NaN            NaN         NaN    23.165171    23.308210   \n",
      "4        NaN        NaN            NaN         NaN    22.924257    23.165171   \n",
      "\n",
      "   Momentum  \n",
      "0       NaN  \n",
      "1       NaN  \n",
      "2       NaN  \n",
      "3       NaN  \n",
      "4       NaN  \n",
      "\n",
      "Dropping rows with NaN values for MSFT...\n",
      "   Unnamed: 0       Price     Close      High       Low      Open     Volume  \\\n",
      "0           0  2010-01-04  6.447412  6.462174  6.398305  6.429938  493729600   \n",
      "1           1  2010-01-05  6.458559  6.495012  6.424516  6.465187  601904800   \n",
      "2           2  2010-01-06  6.355827  6.484167  6.349199  6.458559  552160000   \n",
      "3           3  2010-01-07  6.344076  6.386857  6.297982  6.379325  477131200   \n",
      "4           4  2010-01-08  6.386255  6.386858  6.298286  6.335642  447610800   \n",
      "\n",
      "   SMA_20    EMA_20  RSI  Bollinger_Upper  Bollinger_Lower  10_day_MA  \\\n",
      "0     NaN  6.447412  NaN              NaN              NaN        NaN   \n",
      "1     NaN  6.448473  NaN              NaN              NaN        NaN   \n",
      "2     NaN  6.439650  NaN              NaN              NaN        NaN   \n",
      "3     NaN  6.430548  NaN              NaN              NaN        NaN   \n",
      "4     NaN  6.426329  NaN              NaN              NaN        NaN   \n",
      "\n",
      "   50_day_MA  RSI_SMA_Ratio  Volatility  Close_lag_1  Close_lag_2  Momentum  \n",
      "0        NaN            NaN         NaN          NaN          NaN       NaN  \n",
      "1        NaN            NaN         NaN     6.447412          NaN       NaN  \n",
      "2        NaN            NaN         NaN     6.458559     6.447412       NaN  \n",
      "3        NaN            NaN         NaN     6.355827     6.458559       NaN  \n",
      "4        NaN            NaN         NaN     6.344076     6.355827       NaN  \n",
      "\n",
      "Dropping rows with NaN values for AAPL...\n",
      "   Unnamed: 0       Price     Close      High       Low      Open     Volume  \\\n",
      "0           0  2010-06-29  1.592667  1.666667  1.169333  1.266667  281494500   \n",
      "1           1  2010-06-30  1.588667  2.028000  1.553333  1.719333  257806500   \n",
      "2           2  2010-07-01  1.464000  1.728000  1.351333  1.666667  123282000   \n",
      "3           3  2010-07-02  1.280000  1.540000  1.247333  1.533333   77097000   \n",
      "4           4  2010-07-06  1.074000  1.333333  1.055333  1.333333  103003500   \n",
      "\n",
      "   SMA_20    EMA_20  RSI  Bollinger_Upper  Bollinger_Lower  10_day_MA  \\\n",
      "0     NaN  1.592667  NaN              NaN              NaN        NaN   \n",
      "1     NaN  1.592286  NaN              NaN              NaN        NaN   \n",
      "2     NaN  1.580068  NaN              NaN              NaN        NaN   \n",
      "3     NaN  1.551490  NaN              NaN              NaN        NaN   \n",
      "4     NaN  1.506015  NaN              NaN              NaN        NaN   \n",
      "\n",
      "   50_day_MA  RSI_SMA_Ratio  Volatility  Close_lag_1  Close_lag_2  Momentum  \n",
      "0        NaN            NaN         NaN          NaN          NaN       NaN  \n",
      "1        NaN            NaN         NaN     1.592667          NaN       NaN  \n",
      "2        NaN            NaN         NaN     1.588667     1.592667       NaN  \n",
      "3        NaN            NaN         NaN     1.464000     1.588667       NaN  \n",
      "4        NaN            NaN         NaN     1.280000     1.464000       NaN  \n",
      "\n",
      "Dropping rows with NaN values for TSLA...\n",
      "Remaining rows after dropping NaN: 3223\n",
      "Remaining rows after dropping NaN: 3101\n",
      "Remaining rows after dropping NaN: 3223\n",
      "Remaining rows after dropping NaN: 3223\n",
      "Class distribution for GOOGL:\n",
      "Close\n",
      "1    1805\n",
      "0    1418\n",
      "Name: count, dtype: int64\n",
      "Class distribution for AAPL:\n",
      "Close\n",
      "1    1850\n",
      "0    1373\n",
      "Name: count, dtype: int64\n",
      "Class distribution for TSLA:\n",
      "Close\n",
      "1    1689\n",
      "0    1412\n",
      "Name: count, dtype: int64\n",
      "Class distribution for MSFT:\n",
      "Close\n",
      "1    1853\n",
      "0    1370\n",
      "Name: count, dtype: int64\n",
      "Performing grid search for GOOGL...\n",
      "Performing grid search for TSLA...\n",
      "Performing grid search for AAPL...\n",
      "Performing grid search for MSFT...\n",
      "Best parameters for TSLA: {'max_depth': 15, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Accuracy for TSLA: 0.72\n",
      "Classification Report for TSLA:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.70      0.70       283\n",
      "           1       0.75      0.75      0.75       338\n",
      "\n",
      "    accuracy                           0.72       621\n",
      "   macro avg       0.72      0.72      0.72       621\n",
      "weighted avg       0.72      0.72      0.72       621\n",
      "\n",
      "Model saved to models/TSLA_improved_random_forest.pkl\n",
      "Best parameters for MSFT: {'max_depth': 15, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Accuracy for MSFT: 0.70\n",
      "Classification Report for MSFT:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.64       274\n",
      "           1       0.74      0.75      0.74       371\n",
      "\n",
      "    accuracy                           0.70       645\n",
      "   macro avg       0.69      0.69      0.69       645\n",
      "weighted avg       0.70      0.70      0.70       645\n",
      "\n",
      "Best parameters for AAPL: {'max_depth': 15, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best parameters for GOOGL: {'max_depth': 15, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Model saved to models/MSFT_improved_random_forest.pkl\n",
      "Accuracy for AAPL: 0.72\n",
      "Classification Report for AAPL:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68       275\n",
      "           1       0.77      0.73      0.75       370\n",
      "\n",
      "    accuracy                           0.72       645\n",
      "   macro avg       0.71      0.72      0.71       645\n",
      "weighted avg       0.72      0.72      0.72       645\n",
      "\n",
      "Accuracy for GOOGL: 0.69\n",
      "Classification Report for GOOGL:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.67      0.65       284\n",
      "           1       0.73      0.70      0.72       361\n",
      "\n",
      "    accuracy                           0.69       645\n",
      "   macro avg       0.68      0.69      0.69       645\n",
      "weighted avg       0.69      0.69      0.69       645\n",
      "\n",
      "Model saved to models/AAPL_improved_random_forest.pkl\n",
      "Model saved to models/GOOGL_improved_random_forest.pkl\n",
      "All models trained and saved:\n",
      "models/AAPL_improved_random_forest.pkl\n",
      "models/GOOGL_improved_random_forest.pkl\n",
      "models/MSFT_improved_random_forest.pkl\n",
      "models/TSLA_improved_random_forest.pkl\n"
     ]
    }
   ],
   "source": [
    "tickers = [\"AAPL\", \"GOOGL\", \"MSFT\", \"TSLA\"]\n",
    "train_models_for_all_tickers(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6cb19a-1387-42c9-9c2b-78378e25ed0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "690f3d1c-71a4-4323-bfac-d229a0160944",
   "metadata": {},
   "source": [
    "## Used Logistic Regression, but as expected, model didn't perform well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bf95bc1-d9a3-4abd-801e-21964585b8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# Define the directories\n",
    "DATA_DIR = \"processed_data\"\n",
    "MODEL_DIR = \"models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "def load_and_prepare_data(ticker):\n",
    "    \"\"\"\n",
    "    Load and prepare data for a given ticker.\n",
    "\n",
    "    Parameters:\n",
    "        ticker (str): Stock ticker.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Features (X) and target (y).\n",
    "    \"\"\"\n",
    "    file_path = f\"{DATA_DIR}/{ticker}_historical_prices_.csv\"\n",
    "    df = dd.read_csv(file_path)\n",
    "    \n",
    "    # Ensure necessary columns exist\n",
    "    required_columns = [\"Close\", \"SMA_20\", \"EMA_20\", \"RSI\"]\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Column {col} missing in {ticker} dataset.\")\n",
    "    \n",
    "    # Drop NaN values and prepare features and target\n",
    "    df[\"RSI_SMA_Ratio\"] = df[\"RSI\"] / df[\"SMA_20\"]\n",
    "    df[\"Volatility\"] = df[\"Close\"].rolling(window=20).std()\n",
    "    df[\"Close_lag_1\"] = df[\"Close\"].shift(1)\n",
    "    df[\"Close_lag_2\"] = df[\"Close\"].shift(2)\n",
    "\n",
    "    df = df.dropna()\n",
    "    X = df[[\"SMA_20\", \"EMA_20\", \"RSI\", \"RSI_SMA_Ratio\", \"Volatility\", \"Close_lag_1\", \"Close_lag_2\"]]\n",
    "    # y = (df[\"Close\"].shift(-1) > df[\"Close\"]).astype(int)  # Binary classification: 1 if price goes up, 0 otherwise\n",
    "    y = (df[\"Close\"].shift(-5) > df[\"Close\"]).astype(int)\n",
    "    return X, y\n",
    "\n",
    "def train_logistic_regression(ticker):\n",
    "    \"\"\"\n",
    "    Train a logistic regression model for a specific stock ticker using Dask-ML.\n",
    "\n",
    "    Parameters:\n",
    "        ticker (str): Stock ticker symbol.\n",
    "\n",
    "    Returns:\n",
    "        str: Path to the saved model.\n",
    "    \"\"\"\n",
    "    print(f\"Training Logistic Regression model for {ticker}...\")\n",
    "    \n",
    "    # Step 1: Load and Prepare Data\n",
    "    X, y = load_and_prepare_data(ticker)\n",
    "    X = X.compute()  # Convert Dask DataFrame to Pandas\n",
    "    y = y.compute()\n",
    "\n",
    "    smote = SMOTE(random_state=42)\n",
    "    \n",
    "    # Step 2: Split the Data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "    # Print the new class distribution\n",
    "    print(\"Class distribution after SMOTE:\")\n",
    "    print(pd.Series(y_train_balanced).value_counts())    \n",
    "    # Step 3: Define the Model\n",
    "    model = LogisticRegression(penalty='l2', max_iter=500, solver='lbfgs', class_weight=\"balanced\", random_state=42)\n",
    "    \n",
    "    # Step 4: Hyperparameter Grid\n",
    "    param_grid = {\n",
    "        \"C\": [0.1, 1.0, 10.0],  # Regularization parameter\n",
    "        \"tol\": [1e-4, 1e-3, 1e-2]\n",
    "    }\n",
    "\n",
    "    # Step 5: Distributed Grid Search with Dask-ML\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring=\"accuracy\", n_jobs=-1)\n",
    "    grid_search.fit(X_train_balanced, y_train_balanced)\n",
    "    \n",
    "    # Step 6: Evaluate the Model\n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(f\"Best parameters for {ticker}: {grid_search.best_params_}\")\n",
    "    \n",
    "    y_pred = best_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy for {ticker}: {accuracy:.2f}\")\n",
    "    \n",
    "    # Detailed classification metrics\n",
    "    print(f\"Classification Report for {ticker}:\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Step 7: Save the Model\n",
    "    model_path = f\"{MODEL_DIR}/{ticker}_logistic_regression.pkl\"\n",
    "    joblib.dump(best_model, model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "    \n",
    "    return model_path\n",
    "\n",
    "def train_models_for_all_tickers_logistic(tickers):\n",
    "    \"\"\"\n",
    "    Train Logistic Regression models for all tickers in parallel using Dask.\n",
    "\n",
    "    Parameters:\n",
    "        tickers (list): List of stock tickers.\n",
    "    \"\"\"\n",
    "    futures = [dask.delayed(train_logistic_regression)(ticker) for ticker in tickers]\n",
    "    results = dask.compute(*futures)  # Run tasks in parallel\n",
    "    print(\"All models trained and saved:\")\n",
    "    for result in results:\n",
    "        print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d5d8963-0679-4c67-b815-c7ea7e3a99fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression model for GOOGL...Training Logistic Regression model for AAPL...\n",
      "\n",
      "Training Logistic Regression model for MSFT...\n",
      "Training Logistic Regression model for TSLA...\n",
      "Class distribution after SMOTE:\n",
      "Close\n",
      "0    1482\n",
      "1    1482\n",
      "Name: count, dtype: int64\n",
      "Class distribution after SMOTE:\n",
      "Close\n",
      "0    1482\n",
      "1    1482\n",
      "Name: count, dtype: int64\n",
      "Class distribution after SMOTE:\n",
      "Close\n",
      "0    1482\n",
      "1    1482\n",
      "Name: count, dtype: int64\n",
      "Class distribution after SMOTE:\n",
      "Close\n",
      "0    1482\n",
      "1    1482\n",
      "Name: count, dtype: int64\n",
      "Best parameters for GOOGL: {'C': 10.0, 'tol': 0.0001}\n",
      "Accuracy for GOOGL: 0.56\n",
      "Classification Report for GOOGL:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.43      0.45       274\n",
      "           1       0.61      0.66      0.63       371\n",
      "\n",
      "    accuracy                           0.56       645\n",
      "   macro avg       0.54      0.54      0.54       645\n",
      "weighted avg       0.55      0.56      0.56       645\n",
      "\n",
      "Best parameters for AAPL: {'C': 10.0, 'tol': 0.0001}\n",
      "Model saved to models/GOOGL_logistic_regression.pkl\n",
      "Accuracy for AAPL: 0.56\n",
      "Classification Report for AAPL:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.43      0.45       274\n",
      "           1       0.61      0.66      0.63       371\n",
      "\n",
      "    accuracy                           0.56       645\n",
      "   macro avg       0.54      0.54      0.54       645\n",
      "weighted avg       0.55      0.56      0.56       645\n",
      "\n",
      "Model saved to models/AAPL_logistic_regression.pkl\n",
      "Best parameters for TSLA: {'C': 10.0, 'tol': 0.0001}\n",
      "Accuracy for TSLA: 0.56\n",
      "Classification Report for TSLA:\n",
      "\n",
      "Best parameters for MSFT: {'C': 10.0, 'tol': 0.0001}\n",
      "Accuracy for MSFT: 0.56\n",
      "Classification Report for MSFT:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.43      0.45       274\n",
      "           1       0.61      0.66      0.63       371\n",
      "\n",
      "    accuracy                           0.56       645\n",
      "   macro avg       0.54      0.54      0.54       645\n",
      "weighted avg       0.55      0.56      0.56       645\n",
      "\n",
      "Model saved to models/TSLA_logistic_regression.pkl\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.43      0.45       274\n",
      "           1       0.61      0.66      0.63       371\n",
      "\n",
      "    accuracy                           0.56       645\n",
      "   macro avg       0.54      0.54      0.54       645\n",
      "weighted avg       0.55      0.56      0.56       645\n",
      "\n",
      "Model saved to models/MSFT_logistic_regression.pkl\n",
      "All models trained and saved:\n",
      "models/AAPL_logistic_regression.pkl\n",
      "models/GOOGL_logistic_regression.pkl\n",
      "models/MSFT_logistic_regression.pkl\n",
      "models/TSLA_logistic_regression.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# List of tickers to train on\n",
    "tickers = [\"AAPL\", \"GOOGL\", \"MSFT\", \"TSLA\"]\n",
    "\n",
    "# Train models for all tickers\n",
    "train_models_for_all_tickers_logistic(tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0fddf8-2e4e-4fac-901d-be6e557ec390",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
